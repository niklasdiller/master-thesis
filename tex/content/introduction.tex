\chapter{Introduction} \label{chap:introduction}

% TODO Disclaimer hinzufügen? : Die "gleiche" Variablen manchmal mit anderer schreibweise, weil sie in anderem kontext gemeint sind? zB window_size in DB und windoSize in Java. 


A common and widely known challenge in training and using machine learning models is to find a suitable balance between overfitting and underfitting \cite{vanderaalst2010}. The goal for coming up with valuable predictors for a specific problem therefore is often to create models that neither simply reproduce results gathered from the training data, nor make too broad generalizations. Overfitting would mean that the model would not only learn the underlying pattern of data but also random noise that comes with it. This results in a bad-performing model for new and unseen data, as the model is constantly trying to match its’ predictions with the training data too closely. Underfitting on the other hand happens if a model fails to completely cover the complexity of a specific problem. Because new data points are unfamiliar to the model, the resulting predictions will also be poor and not accurate \cite{montesinoslopez2022}.  It becomes a crucial task for machine learning engineers to balance the amount of the training data and the hyperparameters for machine learning models to find a suitable golden mean of creating models that correctly represent the underlying patterns but is at the same time capable of handling new data points. 

A similar crucial balancing act in machine learning that seems to find much less attention, however, is the equipoise of the concepts of performance and resource awareness. Both principles are essential for a valuable machine learning model: Predictors need to produce accurate results in order to be of value and research has laid an increasing focus on designing resource-aware machine learning systems \cite{rapp2022}. While the two concepts don’t necessarily cancel each other out, there seems to be a trade-off between them when exploring and training models. Good-performing models often make use of a big set of features and complex algorithms and in order to produce a stream of up-to-date predictions, they are often called in short time intervals. Machine learning models of this kind, however, tend to demand a larger number of computational resources, e.g. CPU time, memory consumption, or network utilization. When only looking for the best performing model, i.e. the model that produces the most accurate results, the predictions might become too expensive in regards to memory or battery usage, or simply too computationally complex \cite{preuveneers2020}. Especially in the context of edge computing, this balance between good performance and good resource utilization becomes crucial. Edge computing is a computing paradigm that focuses on processing data at the same place where it is produced: at the edge of the network. In contrast to cloud computing, which works by sending all raw data to a central node to be processed there, edge computing operates on the data near the sensors that produce it. That way, less data needs to be sent on a anyway limited network bandwidth, accounting for faster response times, and less network pressure \cite{shi2016}.

The main motivation for this work are two projects that the Chair of Mobile Systems of the University of Bamberg is carrying out. Both raise the demand of a model set retrieval system that lets the user decide, how significant resource awareness is supposed to be in relation to performance. These projects will be introduced in greater detail in the following chapter. For a model retrieval system to work, several varying machine learning models need to exist first. It was therefore decided to implement a model training pipeline along with the retrieval system itself. As many questions regarding the conceptualization of different parts of the use cases are still open, this work also aims to elaborate various theoretical ideas and concepts regarding resource awareness, prediction horizons, and model scores.

This work will focus on answering the question of how to manage a meaningful balance between performance and resource awareness in the model selection process. In particular, the creation of ensembles or model sets will be discussed from this perspective while applying them to the use cases that this work will refer to. The chapters of this thesis are structured as follows: First, the related research of this work will be presented by introducing several theoretical concepts that serve as a foundation for the upcoming chapters. Thus, model ensembles, resource awareness, performance, the top-k retrieval process as well as the previously mentioned projects that serve as a motivation for this work are explained. The next chapter then will present the assumptions, concepts and overall design of the training pipeline and the top-k retrieval system that were developed. Following, \autoref{chap:implementation} will be devoted to a more practical manner, by going over the decisions that were during the implementation phase of this project. Here, various 
