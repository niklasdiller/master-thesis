@IEEEtranBSTCTL{IEEEexample:BSTcontrol,
CTLdash_repeated_names = "no"
}


@article{amir2018,
  title = {Priority {{Neuron}}: {{A Resource-Aware Neural Network}} for {{Cyber-Physical Systems}}},
  shorttitle = {Priority {{Neuron}}},
  author = {Amir, Maral and Givargis, Tony},
  year = {2018},
  month = nov,
  journal = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
  volume = {37},
  number = {11},
  pages = {2732--2742},
  issn = {1937-4151},
  doi = {10.1109/TCAD.2018.2857319},
  urldate = {2024-07-23},
  abstract = {Advances in sensing, computation, storage, and actuation technologies have entered cyber-physical systems (CPSs) into the smart era where complex control applications requiring high performance are supported. Neural networks (NNs) models are proposed as a predictive model to be used in model predictive control (MPC) applications. However, the ability to efficiently exploit resource hungry NNs in embedded resource-bound settings is a major challenge. In this paper, we propose priority neuron network (PNN), a resource-aware NNs model that can be reconfigured into smaller subnetworks at runtime. This approach enables a tradeoff between the model's computation time and accuracy based on available resources. The PNN model is memory efficient since it stores only one set of parameters to account for various subnetwork sizes. We propose a training algorithm that applies regularization techniques to constrain the activation value of neurons and assigns a priority to each one. We consider the neuron's ordinal number as our priority criteria in that the priority of the neuron is inversely proportional to its ordinal number in the layer. This imposes a relatively sorted order on the activation values. We conduct experiments to employ our PNN as the predictive model of a vehicle in MPC for path tracking. To corroborate the effectiveness of our proposed methodology, we compare it with two state-of-the-art methods for resource-aware NN design. Compared to state-of-the-art work, our approach can cut down the training time by 87\% and reduce the memory storage by 75\% while achieving similar accuracy. Moreover, we decrease the computation overhead for the model reduction process that searches for neurons below a threshold, from O(n) to O (log n ).},
  keywords = {Artificial neural networks,Biological neural networks,Computational modeling,Cyber-physical system,Embedded systems,Mathematical model,model predictive control (MPC),neural networks (NNs),Neurons,Predictive models,resource-aware,Training},
  file = {/Users/niklas/Zotero/storage/6742CBWL/8412508.html}
}

@article{bauer1999,
  title = {An {{Empirical Comparison}} of {{Voting Classification Algorithms}}: {{Bagging}}, {{Boosting}}, and {{Variants}}},
  shorttitle = {An {{Empirical Comparison}} of {{Voting Classification Algorithms}}},
  author = {Bauer, Eric and Kohavi, Ron},
  year = {1999},
  month = jul,
  journal = {Machine Learning},
  volume = {36},
  number = {1},
  pages = {105--139},
  issn = {1573-0565},
  doi = {10.1023/A:1007515423169},
  urldate = {2023-10-25},
  abstract = {Methods for voting classification algorithms, such as Bagging and AdaBoost, have been shown to be very successful in improving the accuracy of certain classifiers for artificial and real-world datasets. We review these algorithms and describe a large empirical study comparing several variants in conjunction with a decision tree inducer (three variants) and a Naive-Bayes inducer. The purpose of the study is to improve our understanding of why and when these algorithms, which use perturbation, reweighting, and combination techniques, affect classification error. We provide a bias and variance decomposition of the error to show how different methods and variants influence these two terms. This allowed us to determine that Bagging reduced variance of unstable methods, while boosting methods (AdaBoost and Arc-x4) reduced both the bias and variance of unstable methods but increased the variance for Naive-Bayes, which was very stable. We observed that Arc-x4 behaves differently than AdaBoost if reweighting is used instead of resampling, indicating a fundamental difference. Voting variants, some of which are introduced in this paper, include: pruning versus no pruning, use of probabilistic estimates, weight perturbations (Wagging), and backfitting of data. We found that Bagging improves when probabilistic estimates in conjunction with no-pruning are used, as well as when the data was backfit. We measure tree sizes and show an interesting positive correlation between the increase in the average tree size in AdaBoost trials and its success in reducing the error. We compare the mean-squared error of voting methods to non-voting methods and show that the voting methods lead to large and significant reductions in the mean-squared errors. Practical problems that arise in implementing boosting algorithms are explored, including numerical instabilities and underflows. We use scatterplots that graphically show how AdaBoost reweights instances, emphasizing not only ``hard'' areas but also outliers and noise.},
  langid = {english},
  keywords = {Bagging,boosting,classification,decision trees,mean-squared error,Naive-Bayes},
  file = {/Users/niklas/Zotero/storage/Q7J8VIW5/Bauer und Kohavi - 1999 - An Empirical Comparison of Voting Classification A.pdf}
}

@inproceedings{borzsony2001,
  title = {The {{Skyline}} Operator},
  booktitle = {Proceedings 17th {{International Conference}} on {{Data Engineering}}},
  author = {Borzsony, S. and Kossmann, D. and Stocker, K.},
  year = {2001},
  pages = {421--430},
  publisher = {IEEE Comput. Soc},
  address = {Heidelberg, Germany},
  doi = {10.1109/ICDE.2001.914855},
  urldate = {2024-07-23},
  abstract = {We propose to extend database systems by a Skyline operation. This operation filters out a set of interesting points from a potentially large set of data points. A point is interesting if it is not dominated by any other point. For example, a hotel might be interesting for somebody traveling to Nassau if no other hotel is both cheaper and closer to the beach. We show how SQL can be extended to pose Skyline queries, present and evaluate alternative algorithms to implement the Skyline operation, and show how this operation can be combined with other database operations (e.g., join and Top N ).},
  isbn = {978-0-7695-1001-9},
  langid = {english},
  file = {/Users/niklas/Zotero/storage/CQDUTDIU/Borzsony et al. - 2001 - The Skyline operator.pdf}
}

@article{brown2005,
  title = {Diversity Creation Methods: A Survey and Categorisation},
  shorttitle = {Diversity Creation Methods},
  author = {Brown, Gavin and Wyatt, Jeremy and Harris, Rachel and Yao, Xin},
  year = {2005},
  month = mar,
  journal = {Information Fusion},
  volume = {6},
  number = {1},
  pages = {5--20},
  issn = {15662535},
  doi = {10.1016/j.inffus.2004.04.004},
  urldate = {2023-11-14},
  langid = {english},
  file = {/Users/niklas/Zotero/storage/XDQGF2IT/Brown et al. - 2005 - Diversity creation methods a survey and categoris.pdf}
}

@article{dehghani2019,
  title = {A {{Quantitative Comparison}} of {{Overlapping}} and {{Non-Overlapping Sliding Windows}} for {{Human Activity Recognition Using Inertial Sensors}}},
  author = {Dehghani, Akbar and Sarbishei, Omid and Glatard, Tristan and Shihab, Emad},
  year = {2019},
  month = nov,
  journal = {Sensors (Basel, Switzerland)},
  volume = {19},
  number = {22},
  pages = {5026},
  issn = {1424-8220},
  doi = {10.3390/s19225026},
  urldate = {2024-05-10},
  abstract = {The sliding window technique is widely used to segment inertial sensor signals, i.e., accelerometers and gyroscopes, for activity recognition. In this technique, the sensor signals are partitioned into fix sized time windows which can be of two types: (1) non-overlapping windows, in which time windows do not intersect, and (2) overlapping windows, in which they do. There is a generalized idea about the positive impact of using overlapping sliding windows on the performance of recognition systems in Human Activity Recognition. In this paper, we analyze the impact of overlapping sliding windows on the performance of Human Activity Recognition systems with different evaluation techniques, namely, subject-dependent cross validation and subject-independent cross validation. Our results show that the performance improvements regarding overlapping windowing reported in the literature seem to be associated with the underlying limitations of subject-dependent cross validation. Furthermore, we do not observe any performance gain from the use of such technique in conjunction with subject-independent cross validation. We conclude that when using subject-independent cross validation, non-overlapping sliding windows reach the same performance as sliding windows. This result has significant implications on the resource usage for training the human activity recognition systems.},
  pmcid = {PMC6891351},
  pmid = {31752158},
  file = {/Users/niklas/Zotero/storage/DAWFJ9F3/Dehghani et al. - 2019 - A Quantitative Comparison of Overlapping and Non-O.pdf}
}

@article{dessain2022,
  title = {Machine Learning Models Predicting Returns: {{Why}} Most Popular Performance Metrics Are Misleading and Proposal for an Efficient Metric},
  shorttitle = {Machine Learning Models Predicting Returns},
  author = {Dessain, Jean},
  year = {2022},
  month = aug,
  journal = {Expert Systems with Applications},
  volume = {199},
  pages = {116970},
  issn = {0957-4174},
  doi = {10.1016/j.eswa.2022.116970},
  urldate = {2024-06-11},
  abstract = {Numerous machine learning models have been developed to achieve the `real-life' financial objective of optimising the risk/return profile of investment strategies. In the current article: (a) we present and classify the most popular performance metrics used in 190 articles analysed. We noticed that, in most articles, no attention is devoted to the criteria used to compare the algorithms. (b) We evaluate the ability of the metrics used in the literature to assess the efficiency of algorithms to improve investments results. We demonstrate that many of the most popular metrics, like mean squared error (MSE) or root mean squared error (RMSE), are inappropriate for this purpose while others, like accuracy or F1, are just weak. We explain why risk-adjusted return-based metrics are best-in-class, although they suffer from statistical limitations and do not allow easy comparison of algorithms across assets or over time. (c) We propose a new discriminant metric that measures the efficiency of AI models to optimize the risk-adjusted return, which is statistically more robust, and which can test the effectiveness and the stability of models over time and across assets.},
  keywords = {Deep learning,Investment efficiency,Machine-learning,Performance evaluation criteria,Stock return predictability,Time series forecasting},
  file = {/Users/niklas/Zotero/storage/AMXZRLZ4/S0957417422003967.html}
}

@incollection{dietterich2000,
  title = {Ensemble {{Methods}} in {{Machine Learning}}},
  booktitle = {Multiple {{Classifier Systems}}},
  author = {Dietterich, Thomas G.},
  editor = {Goos, Gerhard and Hartmanis, Juris and {van Leeuwen}, Jan},
  year = {2000},
  volume = {1857},
  pages = {1--15},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/3-540-45014-9_1},
  urldate = {2023-10-16},
  isbn = {978-3-540-67704-8 978-3-540-45014-6},
  file = {/Users/niklas/Zotero/storage/IL265U8X/Dietterich - 2000 - Ensemble Methods in Machine Learning.pdf}
}

@incollection{eibe2016,
  title = {The {{WEKA Workbench}}},
  booktitle = {Data {{Mining}}: {{Practical Machine Learning Tools}} and {{Techniques}}},
  author = {Eibe, Frank and Hall, Mark A. and Witten, Ian H.},
  year = {2016},
  edition = {Fourth Edition},
  publisher = {Morgan Kaufmann},
  urldate = {2024-04-30},
  file = {/Users/niklas/Zotero/storage/LETE688N/embed.html}
}

@article{erickson2021,
  title = {Magician's {{Corner}}: 9. {{Performance Metrics}} for {{Machine Learning Models}}},
  shorttitle = {Magician's {{Corner}}},
  author = {Erickson, Bradley J. and Kitamura, Felipe},
  year = {2021},
  month = may,
  journal = {Radiology: Artificial Intelligence},
  volume = {3},
  number = {3},
  pages = {e200126},
  issn = {2638-6100},
  doi = {10.1148/ryai.2021200126},
  urldate = {2024-07-08},
  langid = {english}
}

@article{fagin1999,
  title = {Combining {{Fuzzy Information}} from {{Multiple Systems}}},
  author = {Fagin, Ronald},
  year = {1999},
  month = feb,
  journal = {Journal of Computer and System Sciences},
  volume = {58},
  number = {1},
  pages = {83--99},
  issn = {00220000},
  doi = {10.1006/jcss.1998.1600},
  urldate = {2024-01-23},
  langid = {english}
}

@article{fagin2002,
  title = {Combining Fuzzy Information: An Overview},
  shorttitle = {Combining Fuzzy Information},
  author = {Fagin, Ronald},
  year = {2002},
  month = jun,
  journal = {ACM SIGMOD Record},
  volume = {31},
  number = {2},
  pages = {109--118},
  issn = {0163-5808},
  doi = {10.1145/565117.565143},
  urldate = {2023-11-29},
  abstract = {Assume that each object in a database has               m               grades, or scores, one for each of               m               attributes. For example, an object can have a color grade, that tells how red it is, and a shape grade, that tells how round it is. For each attribute, there is a sorted list, which lists each object and its grade under that attribute, sorted by grade (highest grade first). Each object is assigned an overall grade, that is obtained by combining the attribute grades using a fixed monotone               aggregation function,               or               combining rule,               such as min or average. In this overview, we discuss and compare algorithms for determining the top               k               objects, that is,               k               objects with the highest overall grades.},
  langid = {english}
}

@article{fagin2002a,
  title = {Optimal {{Aggregation Algorithms}} for {{Middleware}}},
  author = {Fagin, Ron and Lotem, Amnon and Naor, Moni},
  year = {2002},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.CS/0204046},
  urldate = {2024-01-23},
  abstract = {Let D be a database of N objects where each object has m fields. The objects are given in m sorted lists (where the ith list is sorted according to the ith field). Our goal is to find the top k objects according to a monotone aggregation function t, while minimizing access to the lists. The problem arises in several contexts. In particular Fagin (JCSS 1999) considered it for the purpose of aggregating information in a multimedia database system. We are interested in instance optimality, i.e. that our algorithm will be as good as any other (correct) algorithm on any instance. We provide and analyze several instance optimal algorithms for the task, with various access costs and models.},
  copyright = {Assumed arXiv.org perpetual, non-exclusive license to distribute this article for submissions made before January 2004},
  keywords = {Data Structures and Algorithms (cs.DS),Databases (cs.DB),FOS: Computer and information sciences,H.2.4; F.2.2}
}

@incollection{feurer2019,
  title = {Hyperparameter {{Optimization}}},
  booktitle = {Automated {{Machine Learning}}: {{Methods}}, {{Systems}}, {{Challenges}}},
  author = {Feurer, Matthias and Hutter, Frank},
  editor = {Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
  year = {2019},
  pages = {3--33},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-05318-5_1},
  urldate = {2024-06-06},
  abstract = {Recent interest in complex and computationally expensive machine learning models with many hyperparameters, such as automated machine learning (AutoML) frameworks and deep neural networks, has resulted in a resurgence of research on hyperparameter optimization (HPO). In this chapter, we give an overview of the most prominent approaches for HPO. We first discuss blackbox function optimization methods based on model-free methods and Bayesian optimization. Since the high computational demand of many modern machine learning applications renders pure blackbox optimization extremely costly, we next focus on modern multi-fidelity methods that use (much) cheaper variants of the blackbox function to approximately assess the quality of hyperparameter settings. Lastly, we point to open problems and future research directions.},
  isbn = {978-3-030-05318-5},
  langid = {english},
  file = {/Users/niklas/Zotero/storage/JXTVKY2B/Feurer und Hutter - 2019 - Hyperparameter Optimization.pdf}
}

@incollection{freund1995,
  title = {A Desicion-Theoretic Generalization of on-Line Learning and an Application to Boosting},
  booktitle = {Computational {{Learning Theory}}},
  author = {Freund, Yoav and Schapire, Robert E.},
  editor = {Goos, G. and Hartmanis, J. and Leeuwen, J. and Carbonell, Jaime G. and Siekmann, J{\"o} and Vit{\'a}nyi, Paul},
  year = {1995},
  volume = {904},
  pages = {23--37},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/3-540-59119-2_166},
  urldate = {2023-10-24},
  isbn = {978-3-540-59119-1 978-3-540-49195-8}
}

@techreport{grandini2020,
  type = {White {{Paper}}},
  title = {Metrics for {{Multi-Class Classification}}: An {{Overview}}},
  shorttitle = {Metrics for {{Multi-Class Classification}}},
  author = {Grandini, Margherita and Bagli, Enrico and Visani, Giorgio},
  year = {2020},
  month = aug,
  number = {arXiv:2008.05756},
  eprint = {2008.05756},
  primaryclass = {cs, stat},
  institution = {arXiv},
  urldate = {2024-06-12},
  abstract = {Classification tasks in machine learning involving more than two classes are known by the name of "multi-class classification". Performance indicators are very useful when the aim is to evaluate and compare different classification models or machine learning techniques. Many metrics come in handy to test the ability of a multi-class classifier. Those metrics turn out to be useful at different stage of the development process, e.g. comparing the performance of two different models or analysing the behaviour of the same model by tuning different parameters. In this white paper we review a list of the most promising multi-class metrics, we highlight their advantages and disadvantages and show their possible usages during the development of a classification model.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/niklas/Zotero/storage/3XED53K8/Grandini et al. - 2020 - Metrics for Multi-Class Classification an Overvie.pdf;/Users/niklas/Zotero/storage/BHWBSTVI/2008.html}
}

@book{hastie2009,
  title = {The {{Elements}} of {{Statistical Learning}}},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  year = {2009},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {Springer},
  address = {New York, NY},
  doi = {10.1007/978-0-387-84858-7},
  urldate = {2024-06-11},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-0-387-84857-0 978-0-387-84858-7},
  keywords = {Averaging,Boosting,classification,clustering,data mining,machine learning,Projection pursuit,Random Forest,supervised learning,Support Vector Machine,unsupervised learning},
  file = {/Users/niklas/Zotero/storage/G7YG3Q58/Hastie et al. - 2009 - The Elements of Statistical Learning.pdf}
}

@article{ilyas2008,
  title = {A Survey of Top- {\emph{k}} Query Processing Techniques in Relational Database Systems},
  author = {Ilyas, Ihab F. and Beskales, George and Soliman, Mohamed A.},
  year = {2008},
  month = oct,
  journal = {ACM Computing Surveys},
  volume = {40},
  number = {4},
  pages = {1--58},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/1391729.1391730},
  urldate = {2023-11-29},
  abstract = {Efficient processing of top-               k               queries is a crucial requirement in many interactive environments that involve massive amounts of data. In particular, efficient top-               k               processing in domains such as the Web, multimedia search, and distributed systems has shown a great impact on performance. In this survey, we describe and classify top-               k               processing techniques in relational databases. We discuss different design dimensions in the current techniques including query models, data access methods, implementation levels, data and query certainty, and supported scoring functions. We show the implications of each dimension on the design of the underlying techniques. We also discuss top-               k               queries in XML domain, and show their connections to relational approaches.},
  langid = {english},
  file = {/Users/niklas/Zotero/storage/YA6BCRT9/Ilyas et al. - 2008 - A survey of top- k query processing techniq.pdf}
}

@misc{insomnia,
  title = {Insomnia - {{The Collaborative API Development Platform}}},
  urldate = {2024-05-02},
  abstract = {Leading Open Source API Development Platform for HTTP, REST, GraphQL, gRPC, SOAP, and WebSockets},
  howpublished = {https://insomnia.rest/},
  file = {/Users/niklas/Zotero/storage/EXB36N2G/insomnia.rest.html}
}

@book{james2023,
  title = {{An Introduction to Statistical Learning: with Applications in Python}},
  shorttitle = {{An Introduction to Statistical Learning}},
  author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert and Taylor, Jonathan},
  year = {2023},
  month = jul,
  edition = {1st ed. 2023 Edition},
  publisher = {Springer},
  address = {Cham, Switzerland},
  abstract = {An Introduction to Statistical Learning provides an accessible overview of the field of statistical learning, an essential toolset for making sense of the vast and complex data sets that have emerged in fields ranging from biology to finance, marketing, and astrophysics in the past twenty years. This book presents some of the most important modeling and prediction techniques, along with relevant applications. Topics include linear regression, classification, resampling methods, shrinkage approaches, tree-based methods, support vector machines, clustering, deep learning, survival analysis, multiple testing, and more. Color graphics and real-world examples are used to illustrate the methods presented. This book is targeted at statisticians and non-statisticians alike, who wish to use cutting-edge statistical learning techniques to analyze their data. Four of the authors co-wrote An Introduction to Statistical Learning, With Applications in R(ISLR), which has become a mainstay of undergraduate and graduate classrooms worldwide, as well as an important reference book for data scientists. One of the keys to its success was that each chapter contains a tutorial on implementing the analyses and methods presented in the R scientific computing environment. However, in recent years Python has become a popular language for data science, and there has been increasing demand for a Python-based alternative to ISLR. Hence, this book (ISLP) covers the same materials as ISLR but with labs implemented in Python. These labs will be useful both for Python novices, as well as experienced users.},
  isbn = {978-3-031-38746-3},
  langid = {Englisch}
}

@misc{kulhari,
  title = {Combining {{Fuzzy Information}} - {{Top-k Query Algorithms}}},
  author = {Kulhari, Sanjay},
  urldate = {2023-11-22}
}

@book{kuncheva2004,
  title = {Combining {{Pattern Classifiers}}: {{Methods}} and {{Algorithms}}},
  shorttitle = {Combining {{Pattern Classifiers}}},
  author = {Kuncheva, Ludmila I.},
  year = {2004},
  month = jul,
  edition = {1},
  publisher = {Wiley},
  doi = {10.1002/0471660264},
  urldate = {2023-10-30},
  isbn = {978-0-471-21078-8 978-0-471-66026-2},
  langid = {english}
}

@inproceedings{li2006,
  title = {Supporting Ad-Hoc Ranking Aggregates},
  booktitle = {Proceedings of the 2006 {{ACM SIGMOD}} International Conference on {{Management}} of Data},
  author = {Li, Chengkai and {Chen-Chuan Chang}, Kevin and Ilyas, Ihab F.},
  year = {2006},
  month = jun,
  pages = {61--72},
  publisher = {ACM},
  address = {Chicago IL USA},
  doi = {10.1145/1142473.1142481},
  urldate = {2024-07-23},
  isbn = {978-1-59593-434-5},
  langid = {english},
  file = {/Users/niklas/Zotero/storage/LZSTMVF3/Li et al. - 2006 - Supporting ad-hoc ranking aggregates.pdf}
}

@article{lin2003,
  title = {Performance Analysis of Pattern Classifier Combination by Plurality Voting},
  author = {Lin, Xiaofan and Yacoub, Sherif and Burns, John and Simske, Steven},
  year = {2003},
  month = aug,
  journal = {Pattern Recognition Letters},
  volume = {24},
  number = {12},
  pages = {1959--1969},
  issn = {01678655},
  doi = {10.1016/S0167-8655(03)00035-7},
  urldate = {2023-10-30},
  langid = {english}
}

@article{madrid2019,
  title = {A {{Top-K Retrieval}} Algorithm Based on a Decomposition of Ranking Functions},
  author = {Madrid, Nicol{\'a}s and Rusnok, Pavel},
  year = {2019},
  month = feb,
  journal = {Information Sciences},
  volume = {474},
  pages = {136--153},
  issn = {00200255},
  doi = {10.1016/j.ins.2018.09.014},
  urldate = {2023-11-29},
  langid = {english}
}

@misc{marco2019,
  title = {Optimizing {{Deep Learning Inference}} on {{Embedded Systems Through Adaptive Model Selection}}},
  author = {Marco, Vicent Sanz and Taylor, Ben and Wang, Zheng and Elkhatib, Yehia},
  year = {2019},
  month = nov,
  number = {arXiv:1911.04946},
  eprint = {1911.04946},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1911.04946},
  urldate = {2024-06-17},
  abstract = {Deep neural networks ( DNNs ) are becoming a key enabling technology for many application domains. However, on-device inference on battery-powered, resource-constrained embedding systems is often infeasible due to prohibitively long inferencing time and resource requirements of many DNNs. Offloading computation into the cloud is often unacceptable due to privacy concerns, high latency, or the lack of connectivity. While compression algorithms often succeed in reducing inferencing times, they come at the cost of reduced accuracy. This paper presents a new, alternative approach to enable efficient execution of DNNs on embedded devices. Our approach dynamically determines which DNN to use for a given input, by considering the desired accuracy and inference time. It employs machine learning to develop a low-cost predictive model to quickly select a pre-trained DNN to use for a given input and the optimization constraint. We achieve this by first off-line training a predictive model, and then using the learned model to select a DNN model to use for new, unseen inputs. We apply our approach to two representative DNN domains: image classification and machine translation. We evaluate our approach on a Jetson TX2 embedded deep learning platform and consider a range of influential DNN models including convolutional and recurrent neural networks. For image classification, we achieve a 1.8x reduction in inference time with a 7.52\% improvement in accuracy, over the most-capable single DNN model. For machine translation, we achieve a 1.34x reduction in inference time over the most-capable single model, with little impact on the quality of translation.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Distributed Parallel and Cluster Computing,Computer Science - Machine Learning,Computer Science - Performance},
  file = {/Users/niklas/Zotero/storage/4Z7D3Z4J/Marco et al. - 2019 - Optimizing Deep Learning Inference on Embedded Sys.pdf;/Users/niklas/Zotero/storage/BWEXPMMT/1911.html}
}

@inproceedings{martinez-munoz2004,
  title = {Aggregation Ordering in Bagging},
  booktitle = {Proc. of the {{IASTED International Conference}} on {{Artificial Intelligence}} and {{Applications}}},
  author = {{Mart{\'i}nez-Mu{\~n}oz}, Gonzalo and Su{\'a}rez, Alberto},
  year = {2004},
  pages = {258--263},
  abstract = {The order in which classifiers are aggregated in ensemble methods can be an important tool in the identification of subsets of classifiers that, when combined, perform better than the whole ensemble. Ensembles with randomly ordered classifiers usually exhibit a generalization error that decreases as the number of classifiers that are aggregated increases. If an appropriate order for aggregation is chosen, the generalization error reaches, at intermediate numbers of classifiers, a minimum, which lies below the asymptotic error of the ensemble. This work presents some heuristics that exploit the relations between the classifiers in a bagging ensemble to identify the appropriate ordering and then select a subset for aggregation according to a desired amount pruning. The resulting subensembles are smaller and improve the classification performance of the original ensemble.},
  file = {/Users/niklas/Zotero/storage/JUTSRFKI/Martínez-Muñoz und Suárez - 2004 - Aggregation ordering in bagging.pdf}
}

@book{mckinney2022,
  title = {{Python for Data Analysis: Data Wrangling with Pandas, NumPy, and Jupyter}},
  shorttitle = {{Python for Data Analysis}},
  author = {McKinney, Wes},
  year = {2022},
  month = sep,
  edition = {3rd Edition},
  publisher = {O'Reilly Media},
  address = {Beijing Boston Farnham Sebastopol Tokyo},
  abstract = {Get the definitive handbook for manipulating, processing, cleaning, and crunching datasets in Python. Updated for Python 3.10 and pandas 1.4, the third edition of this hands-on guide is packed with practical case studies that show you how to solve a broad set of data analysis problems effectively. You'll learn the latest versions of pandas, NumPy, and Jupyter in the process.Written by Wes McKinney, the creator of the Python pandas project, this book is a practical, modern introduction to data science tools in Python. It's ideal for analysts new to Python and for Python programmers new to data science and scientific computing. Data files and related material are available on GitHub.Use the Jupyter notebook and IPython shell for exploratory computingLearn basic and advanced features in NumPyGet started with data analysis tools in the pandas libraryUse flexible tools to load, clean, transform, merge, and reshape dataCreate informative visualizations with matplotlibApply the pandas groupby facility to slice, dice, and summarize datasetsAnalyze and manipulate regular and irregular time series dataLearn how to solve real-world data analysis problems with thorough, detailed examples},
  isbn = {978-1-09-810403-0},
  langid = {Englisch}
}

@incollection{montesinoslopez2022,
  title = {Overfitting, {{Model Tuning}}, and {{Evaluation}} of {{Prediction Performance}}},
  booktitle = {Multivariate {{Statistical Machine Learning Methods}} for {{Genomic Prediction}}},
  author = {Montesinos L{\'o}pez, Osval Antonio and Montesinos L{\'o}pez, Abelardo and Crossa, Jose},
  editor = {Montesinos L{\'o}pez, Osval Antonio and Montesinos L{\'o}pez, Abelardo and Crossa, Jos{\'e}},
  year = {2022},
  pages = {109--139},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-89010-0_4},
  urldate = {2024-07-02},
  abstract = {The overfitting phenomenon happens when a statistical machine learning model learns very well about the noise as well as the signal that is present in the training data. On the other hand, an underfitted phenomenon occurs when only a few predictors are included in the statistical machine learning model that represents the complete structure of the data pattern poorly. This problem also arises when the training data set is too small and thus an underfitted model does a poor job of fitting the training data and unsatisfactorily predicts new data points. This chapter describes the importance of the trade-off between prediction accuracy and model interpretability, as well as the difference between explanatory and predictive modeling: Explanatory modeling minimizes bias, whereas predictive modeling seeks to minimize the combination of bias and estimation variance. We assess the importance and different methods of cross-validation as well as the importance and strategies of tuning that are key to the successful use of some statistical machine learning methods. We explain the most important metrics for evaluating the prediction performance for continuous, binary, categorical, and count response variables.},
  isbn = {978-3-030-89010-0},
  langid = {english},
  keywords = {Cross-validation,Metrics of prediction performance,Model interpretability,Overfitting,Prediction accuracy},
  file = {/Users/niklas/Zotero/storage/723KX2RT/Montesinos López et al. - 2022 - Overfitting, Model Tuning, and Evaluation of Predi.pdf}
}

@article{preuveneers2020,
  title = {Resource {{Usage}} and {{Performance Trade-offs}} for {{Machine Learning Models}} in {{Smart Environments}}},
  author = {Preuveneers, Davy and Tsingenopoulos, Ilias and Joosen, Wouter},
  year = {2020},
  month = jan,
  journal = {Sensors},
  volume = {20},
  number = {4},
  pages = {1176},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1424-8220},
  doi = {10.3390/s20041176},
  urldate = {2024-07-03},
  abstract = {The application of artificial intelligence enhances the ability of sensor and networking technologies to realize smart systems that sense, monitor and automatically control our everyday environments. Intelligent systems and applications often automate decisions based on the outcome of certain machine learning models. They collaborate at an ever increasing scale, ranging from smart homes and smart factories to smart cities. The best performing machine learning model, its architecture and parameters for a given task are ideally automatically determined through a hyperparameter tuning process. At the same time, edge computing is an emerging distributed computing paradigm that aims to bring computation and data storage closer to the location where they are needed to save network bandwidth or reduce the latency of requests. The challenge we address in this work is that hyperparameter tuning does not take into consideration resource trade-offs when selecting the best model for deployment in smart environments. The most accurate model might be prohibitively expensive to computationally evaluate on a resource constrained node at the edge of the network. We propose a multi-objective optimization solution to find acceptable trade-offs between model accuracy and resource consumption to enable the deployment of machine learning models in resource constrained smart environments. We demonstrate the feasibility of our approach by means of an anomaly detection use case. Additionally, we evaluate the extent that transfer learning techniques can be applied to reduce the amount of training required by reusing previous models, parameters and trade-off points from similar settings.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {hyperparameter tuning,machine learning,resource optimization,smart environments},
  file = {/Users/niklas/Zotero/storage/ARRRZ9LI/Preuveneers et al. - 2020 - Resource Usage and Performance Trade-offs for Mach.pdf}
}

@inproceedings{rapp2022,
  title = {{{DISTREAL}}: {{Distributed Resource-Aware Learning}} in {{Heterogeneous Systems}}},
  shorttitle = {{{DISTREAL}}},
  booktitle = {Proc. of the {{AAAI Conference}} on {{Artificial Intelligence}} 36},
  author = {Rapp, Martin and Khalili, Ramin and Pfeiffer, Kilian and Henkel, J{\"o}rg},
  year = {2022},
  month = apr,
  eprint = {2112.08761},
  primaryclass = {cs},
  pages = {8062--8071},
  urldate = {2024-06-19},
  abstract = {We study the problem of distributed training of neural networks (NNs) on devices with heterogeneous, limited, and time-varying availability of computational resources. We present an adaptive, resource-aware, on-device learning mechanism, DISTREAL, which is able to fully and efficiently utilize the available resources on devices in a distributed manner, increasing the convergence speed. This is achieved with a dropout mechanism that dynamically adjusts the computational complexity of training an NN by randomly dropping filters of convolutional layers of the model. Our main contribution is the introduction of a design space exploration (DSE) technique, which finds Pareto-optimal per-layer dropout vectors with respect to resource requirements and convergence speed of the training. Applying this technique, each device is able to dynamically select the dropout vector that fits its available resource without requiring any assistance from the server. We implement our solution in a federated learning (FL) system, where the availability of computational resources varies both between devices and over time, and show through extensive evaluation that we are able to significantly increase the convergence speed over the state of the art without compromising on the final accuracy.},
  langid = {english},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/niklas/Zotero/storage/DQ3XXNMA/Rapp et al. - 2022 - DISTREAL Distributed Resource-Aware Learning in H.pdf}
}

@article{rokach2010,
  title = {Ensemble-Based Classifiers},
  author = {Rokach, Lior},
  year = {2010},
  month = feb,
  journal = {Artificial Intelligence Review},
  volume = {33},
  number = {1},
  pages = {1--39},
  issn = {1573-7462},
  doi = {10.1007/s10462-009-9124-7},
  urldate = {2023-10-24},
  abstract = {The idea of ensemble methodology is to build a predictive model by integrating multiple models. It is well-known that ensemble methods can be used for improving prediction performance. Researchers from various disciplines such as statistics and AI considered the use of ensemble methodology. This paper, review existing ensemble techniques and can be served as a tutorial for practitioners who are interested in building ensemble based systems.},
  langid = {english},
  keywords = {Boosting,Classification,Ensemble of classifiers,Supervised learning},
  file = {/Users/niklas/Zotero/storage/BD4WR846/Rokach - 2010 - Ensemble-based classifiers.pdf}
}

@article{schmeling2021,
  title = {Training and {{Validating}} a {{Machine Learning Model}} for the {{Sensor-Based Monitoring}} of {{Lying Behavior}} in {{Dairy Cows}} on {{Pasture}} and in the {{Barn}}},
  author = {Schmeling, Lara and Elmamooz, Golnaz and Hoang, Phan Thai and Kozar, Anastasiia and Nicklas, Daniela and Sünkel, Michael and Thurner, Stefan and Rauch, Elke},
  year = {2021},
  month = sep,
  journal = {Animals},
  volume = {11},
  number = {9},
  pages = {2660},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2076-2615},
  doi = {10.3390/ani11092660},
  urldate = {2024-07-22},
  abstract = {Monitoring systems assist farmers in monitoring the health of dairy cows by predicting behavioral patterns (e.g., lying) and their changes with machine learning models. However, the available systems were developed either for indoors or for pasture and fail to predict the behavior in other locations. Therefore, the goal of our study was to train and evaluate a model for the prediction of lying on a pasture and in the barn. On three farms, 7--11 dairy cows each were equipped with the prototype of the monitoring system containing an accelerometer, a magnetometer and a gyroscope. Video observations on the pasture and in the barn provided ground truth data. We used 34.5 h of datasets from pasture for training and 480.5 h from both locations for evaluating. In comparison, random forest, an orientation-independent feature set with 5 s windows without overlap, achieved the highest accuracy. Sensitivity, specificity and accuracy were 95.6\%, 80.5\% and 87.4\%, respectively. Accuracy on the pasture (93.2\%) exceeded accuracy in the barn (81.4\%). Ruminating while standing was the most confused with lying. Out of individual lying bouts, 95.6 and 93.4\% were identified on the pasture and in the barn, respectively. Adding a model for standing up events and lying down events could improve the prediction of lying in the barn.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {accelerometer,behavior recognition,classification,grazing,gyroscope,precision livestock farming},
  file = {/Users/niklas/Zotero/storage/DG6HS6VN/Schmeling et al. - 2021 - Training and Validating a Machine Learning Model f.pdf}
}

@article{shi2016,
  title = {Edge {{Computing}}: {{Vision}} and {{Challenges}}},
  shorttitle = {Edge {{Computing}}},
  author = {Shi, Weisong and Cao, Jie and Zhang, Quan and Li, Youhuizi and Xu, Lanyu},
  year = {2016},
  month = oct,
  journal = {IEEE Internet of Things Journal},
  volume = {3},
  number = {5},
  pages = {637--646},
  issn = {2327-4662},
  doi = {10.1109/JIOT.2016.2579198},
  urldate = {2024-07-03},
  abstract = {The proliferation of Internet of Things (IoT) and the success of rich cloud services have pushed the horizon of a new computing paradigm, edge computing, which calls for processing the data at the edge of the network. Edge computing has the potential to address the concerns of response time requirement, battery life constraint, bandwidth cost saving, as well as data safety and privacy. In this paper, we introduce the definition of edge computing, followed by several case studies, ranging from cloud offloading to smart home and city, as well as collaborative edge to materialize the concept of edge computing. Finally, we present several challenges and opportunities in the field of edge computing, and hope this paper will gain attention from the community and inspire more research in this direction.},
  keywords = {Bandwidth,Cloud computing,Data privacy,Edge computing,Internet of things,Internet of Things (IoT),Mobile handsets,smart home and city,Smart homes,Time factors},
  file = {/Users/niklas/Zotero/storage/DDADKX42/7488250.html}
}

@book{silberschatz2010,
  title = {{Database System Concepts}},
  author = {Silberschatz, Abraham and Korth, Henry F. and Sudarshan, S.},
  year = {2010},
  month = jan,
  edition = {6},
  publisher = {McGraw Hill Higher Education},
  address = {New York},
  abstract = {Database System Concepts by Silberschatz, Korth and Sudarshan is now in its 6th edition and is one of the cornerstone texts of database education. It presents the fundamental concepts of database management in an intuitive manner geared toward allowing students to begin working with databases as quickly as possible.The text is designed for a first course in databases at the junior/senior undergraduate level or the first year graduate level. It also contains additional material that can be used as supplements or as introductory material for an advanced course. Because the authors present concepts as intuitive descriptions, a familiarity with basic data structures, computer organization, and a high-level programming language are the only prerequisites. Important theoretical results are covered, but formal proofs are omitted. In place of proofs, figures and examples are used to suggest why a result is true.},
  isbn = {978-0-07-352332-3},
  langid = {Englisch}
}

@inproceedings{sunkel2022,
  title = {Resource-{{Aware Classification}} via {{Model Management Enabled Data Stream Optimization}}},
  booktitle = {2022 {{IEEE International Conference}} on {{Pervasive Computing}} and {{Communications}} ({{PerCom}})},
  author = {Sünkel, Michael and Elmamooz, Golnaz and Grawunder, Marco and Hoang, Phan Thai and Rauch, Elke and Schmeling, Lara and Thurner, Stefan and Nicklas, Daniela},
  year = {2022},
  pages = {23--33},
  doi = {10.1109/PerCom53586.2022.9762391},
  urldate = {2024-06-19},
  abstract = {The integration of machine learning (ML) approaches in sensor-based applications in the field of pervasive computing is becoming increasingly prominent due to the increasing number of sensor-based applications in general and the continuous adaption of ML approaches to new domains. Several ML models are used within a processing pipeline that operates on the same sensor data. Still, the cloud computing approach is a straightforward solution where all sensor data is sent to the cloud before processing, which is inefficient according to resource utilization. Appropriate management of the different processing tasks for ML models enhances resource utilization.This paper proposes an architecture for resource-aware classification empowered by an ML model management (MLMM) framework and a distributed data stream management system (DDSMS). First, the classification pipeline is decomposed and implemented as data stream operators. Second, ML models are retrieved from an MLMM framework considering preprocessing, segmentation, and feature alignment to enable an effective redundancy elimination. Finally, the classification pipeline is deployed using resource-aware operator placement optimization. The evaluation results on a real-world scenario of a sensor-based activity classification pipeline for dairy cows show that our approach can reduce network utilization up to 98.9\%.},
  langid = {american},
  file = {/Users/niklas/Zotero/storage/8K5GD9ED/9762391.html}
}

@inproceedings{tann2016,
  title = {Runtime Configurable Deep Neural Networks for Energy-Accuracy Trade-Off},
  booktitle = {Proceedings of the {{Eleventh IEEE}}/{{ACM}}/{{IFIP International Conference}} on {{Hardware}}/{{Software Codesign}} and {{System Synthesis}}},
  author = {Tann, Hokchhay and Hashemi, Soheil and Bahar, R. Iris and Reda, Sherief},
  year = {2016},
  month = oct,
  series = {{{CODES}} '16},
  pages = {1--10},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2968456.2968458},
  urldate = {2024-07-23},
  abstract = {We present a novel dynamic configuration technique for deep neural networks that permits step-wise energy-accuracy tradeoffs during runtime. Our configuration technique adjusts the number of channels in the network dynamically depending on response time, power, and accuracy targets. To enable this dynamic configuration technique, we co-design a new training algorithm, where the network is incrementally trained such that the weights in channels trained in earlier steps are fixed. Our technique provides the flexibility of multiple networks while storing and utilizing one set of weights. We evaluate our techniques using both an ASIC-based hardware accelerator as well as a low-power embedded GPGPU and show that our approach leads to only a small or negligible loss in the final network accuracy. We analyze the performance of our proposed methodology using three well-known networks for MNIST, CIFAR-10, and SVHN datasets, and we show that we are able to achieve up to 95\% energy reduction with less than 1\% accuracy loss across the three benchmarks. In addition, compared to prior work on dynamic network reconfiguration, we show that our approach leads to approximately 50\% savings in storage requirements, while achieving similar accuracy.},
  isbn = {978-1-4503-4483-8},
  file = {/Users/niklas/Zotero/storage/BEC6SNRG/Tann et al. - 2016 - Runtime configurable deep neural networks for ener.pdf}
}

@article{vanderaalst2010,
  title = {Process Mining: A Two-Step Approach to Balance between Underfitting and Overfitting},
  shorttitle = {Process Mining},
  author = {{van der Aalst}, W. M. P. and Rubin, V. and Verbeek, H. M. W. and {van Dongen}, B. F. and Kindler, E. and G{\"u}nther, C. W.},
  year = {2010},
  month = jan,
  journal = {Software \& Systems Modeling},
  volume = {9},
  number = {1},
  pages = {87--111},
  issn = {1619-1374},
  doi = {10.1007/s10270-008-0106-z},
  urldate = {2024-07-02},
  abstract = {Process mining includes the automated discovery of processes from event logs. Based on observed events (e.g., activities being executed or messages being exchanged) a process model is constructed. One of the essential problems in process mining is that one cannot assume to have seen all possible behavior. At best, one has seen a representative subset. Therefore, classical synthesis techniques are not suitable as they aim at finding a model that is able to exactly reproduce the log. Existing process mining techniques try to avoid such ``overfitting'' by generalizing the model to allow for more behavior. This generalization is often driven by the representation language and very crude assumptions about completeness. As a result, parts of the model are ``overfitting'' (allow only for what has actually been observed) while other parts may be ``underfitting'' (allow for much more behavior without strong support for it). None of the existing techniques enables the user to control the balance between ``overfitting'' and ``underfitting''. To address this, we propose a two-step approach. First, using a configurable approach, a transition system is constructed. Then, using the ``theory of regions'', the model is synthesized. The approach has been implemented in the context of ProM and overcomes many of the limitations of traditional approaches.},
  langid = {english},
  keywords = {Business Process,Customer Relationship Management,Process Mining,Region Theory,Transition System},
  file = {/Users/niklas/Zotero/storage/MLMM2VD8/van der Aalst et al. - 2010 - Process mining a two-step approach to balance bet.pdf}
}

@inproceedings{yu2018,
  title = {Slimmable {{Neural Networks}}},
  booktitle = {2019 {{International Conference}} on {{Learning Representations}} ({{ICLR}})},
  author = {Yu, Jiahui and Yang, Linjie and Xu, Ning and Yang, Jianchao and Huang, Thomas},
  year = {2018},
  month = dec,
  eprint = {1812.08928},
  primaryclass = {cs},
  doi = {10.48550/arXiv.1812.08928},
  urldate = {2024-07-23},
  abstract = {We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime. Instead of training individual networks with different width configurations, we train a shared network with switchable batch normalization. At runtime, the network can adjust its width on the fly according to on-device benchmarks and resource constraints, rather than downloading and offloading different models. Our trained networks, named slimmable neural networks, achieve similar (and in many cases better) ImageNet classification accuracy than individually trained models of MobileNet v1, MobileNet v2, ShuffleNet and ResNet-50 at different widths respectively. We also demonstrate better performance of slimmable models compared with individual ones across a wide range of applications including COCO bounding-box object detection, instance segmentation and person keypoint detection without tuning hyper-parameters. Lastly we visualize and discuss the learned features of slimmable networks. Code and models are available at: https://github.com/JiahuiYu/slimmable\_networks},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/niklas/Zotero/storage/MGYZYWVY/Yu et al. - 2018 - Slimmable Neural Networks.pdf;/Users/niklas/Zotero/storage/UDPKCIZZ/1812.html}
}

@book{zhou2012,
  title = {Ensemble {{Methods}}: {{Foundations}} and {{Algorithms}}},
  shorttitle = {Ensemble Methods},
  author = {Zhou, Zhi-Hua},
  year = {2012},
  series = {Machine {{Learning}} \& {{Pattern Recognition Series}}},
  publisher = {CRC Press, Taylor \& Francis},
  address = {Boca Raton, Fla.},
  abstract = {"This comprehensive book presents an in-depth and systematic introduction to ensemble methods for researchers in machine learning, data mining, and related areas. It helps readers solve modem problems in machine learning using these methods. The author covers the spectrum of research in ensemble methods, including such famous methods as boosting, bagging, and rainforest, along with current directions and methods not sufficiently addressed in other books. Chapters explore cutting-edge topics, such as semi-supervised ensembles, cluster ensembles, and comprehensibility, as well as successful applications"--},
  isbn = {978-1-4398-3003-1},
  langid = {english},
  file = {/Users/niklas/Zotero/storage/MKAH7SZN/Zhou - 2012 - Ensemble methods foundations and algorithms.pdf}
}
