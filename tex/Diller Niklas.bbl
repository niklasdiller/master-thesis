% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{fagin1999}
R.~Fagin, ``Combining {{Fuzzy Information}} from {{Multiple Systems}},'' \emph{Journal of Computer and System Sciences}, vol.~58, no.~1, pp. 83--99, Feb. 1999.

\bibitem{fagin2002a}
R.~Fagin, A.~Lotem, and M.~Naor, ``Optimal {{Aggregation Algorithms}} for {{Middleware}},'' 2002.

\bibitem{vanderaalst2010}
W.~M.~P. {van der Aalst}, V.~Rubin, H.~M.~W. Verbeek, B.~F. {van Dongen}, E.~Kindler, and C.~W. G{\"u}nther, ``Process mining: A two-step approach to balance between underfitting and overfitting,'' \emph{Software \& Systems Modeling}, vol.~9, no.~1, pp. 87--111, Jan. 2010.

\bibitem{montesinoslopez2022}
O.~A. Montesinos~L{\'o}pez, A.~Montesinos~L{\'o}pez, and J.~Crossa, ``Overfitting, {{Model Tuning}}, and {{Evaluation}} of {{Prediction Performance}},'' in \emph{Multivariate {{Statistical Machine Learning Methods}} for {{Genomic Prediction}}}, O.~A. Montesinos~L{\'o}pez, A.~Montesinos~L{\'o}pez, and J.~Crossa, Eds.\hskip 1em plus 0.5em minus 0.4em\relax Cham: Springer International Publishing, 2022, pp. 109--139.

\bibitem{rapp2022}
M.~Rapp, R.~Khalili, K.~Pfeiffer, and J.~Henkel, ``{{DISTREAL}}: {{Distributed Resource-Aware Learning}} in {{Heterogeneous Systems}},'' in \emph{Proc. of the {{AAAI Conference}} on {{Artificial Intelligence}} 36}, Apr. 2022, pp. 8062--8071.

\bibitem{preuveneers2020}
D.~Preuveneers, I.~Tsingenopoulos, and W.~Joosen, ``Resource {{Usage}} and {{Performance Trade-offs}} for {{Machine Learning Models}} in {{Smart Environments}},'' \emph{Sensors}, vol.~20, no.~4, p. 1176, Jan. 2020.

\bibitem{shi2016}
W.~Shi, J.~Cao, Q.~Zhang, Y.~Li, and L.~Xu, ``Edge {{Computing}}: {{Vision}} and {{Challenges}},'' \emph{IEEE Internet of Things Journal}, vol.~3, no.~5, pp. 637--646, Oct. 2016.

\bibitem{zhou2012}
Z.-H. Zhou, \emph{Ensemble {{Methods}}: {{Foundations}} and {{Algorithms}}}, ser. Machine {{Learning}} \& {{Pattern Recognition Series}}.\hskip 1em plus 0.5em minus 0.4em\relax Boca Raton, Fla.: CRC Press, Taylor \& Francis, 2012.

\bibitem{james2023}
G.~James, D.~Witten, T.~Hastie, R.~Tibshirani, and J.~Taylor, \emph{{An Introduction to Statistical Learning: with Applications in Python}}, 1st~ed.\hskip 1em plus 0.5em minus 0.4em\relax Cham, Switzerland: Springer, Jul. 2023.

\bibitem{schmeling2021}
L.~Schmeling, G.~Elmamooz, P.~T. Hoang, A.~Kozar, D.~Nicklas, M.~Sünkel, S.~Thurner, and E.~Rauch, ``Training and {{Validating}} a {{Machine Learning Model}} for the {{Sensor-Based Monitoring}} of {{Lying Behavior}} in {{Dairy Cows}} on {{Pasture}} and in the {{Barn}},'' \emph{Animals}, vol.~11, no.~9, p. 2660, Sep. 2021.

\bibitem{sunkel2022}
M.~Sünkel, G.~Elmamooz, M.~Grawunder, P.~T. Hoang, E.~Rauch, L.~Schmeling, S.~Thurner, and D.~Nicklas, ``Resource-{{Aware Classification}} via {{Model Management Enabled Data Stream Optimization}},'' in \emph{2022 {{IEEE International Conference}} on {{Pervasive Computing}} and {{Communications}} ({{PerCom}})}, 2022, pp. 23--33.

\bibitem{dietterich2000}
T.~G. Dietterich, ``Ensemble {{Methods}} in {{Machine Learning}},'' in \emph{Multiple {{Classifier Systems}}}, G.~Goos, J.~Hartmanis, and J.~{van Leeuwen}, Eds.\hskip 1em plus 0.5em minus 0.4em\relax Berlin, Heidelberg: Springer Berlin Heidelberg, 2000, vol. 1857, pp. 1--15.

\bibitem{rokach2010}
L.~Rokach, ``Ensemble-based classifiers,'' \emph{Artificial Intelligence Review}, vol.~33, no.~1, pp. 1--39, Feb. 2010.

\bibitem{freund1995}
Y.~Freund and R.~E. Schapire, ``A desicion-theoretic generalization of on-line learning and an application to boosting,'' in \emph{Computational {{Learning Theory}}}, G.~Goos, J.~Hartmanis, J.~Leeuwen, J.~G. Carbonell, J.~Siekmann, and P.~Vit{\'a}nyi, Eds.\hskip 1em plus 0.5em minus 0.4em\relax Berlin, Heidelberg: Springer Berlin Heidelberg, 1995, vol. 904, pp. 23--37.

\bibitem{martinez-munoz2004}
G.~{Mart{\'i}nez-Mu{\~n}oz} and A.~Su{\'a}rez, ``Aggregation ordering in bagging,'' in \emph{Proc. of the {{IASTED International Conference}} on {{Artificial Intelligence}} and {{Applications}}}, 2004, pp. 258--263.

\bibitem{bauer1999}
E.~Bauer and R.~Kohavi, ``An {{Empirical Comparison}} of {{Voting Classification Algorithms}}: {{Bagging}}, {{Boosting}}, and {{Variants}},'' \emph{Machine Learning}, vol.~36, no.~1, pp. 105--139, Jul. 1999.

\bibitem{lin2003}
X.~Lin, S.~Yacoub, J.~Burns, and S.~Simske, ``Performance analysis of pattern classifier combination by plurality voting,'' \emph{Pattern Recognition Letters}, vol.~24, no.~12, pp. 1959--1969, Aug. 2003.

\bibitem{kuncheva2004}
L.~I. Kuncheva, \emph{Combining {{Pattern Classifiers}}: {{Methods}} and {{Algorithms}}}, 1st~ed.\hskip 1em plus 0.5em minus 0.4em\relax Wiley, Jul. 2004.

\bibitem{brown2005}
G.~Brown, J.~Wyatt, R.~Harris, and X.~Yao, ``Diversity creation methods: A survey and categorisation,'' \emph{Information Fusion}, vol.~6, no.~1, pp. 5--20, Mar. 2005.

\bibitem{amir2018}
M.~Amir and T.~Givargis, ``Priority {{Neuron}}: {{A Resource-Aware Neural Network}} for {{Cyber-Physical Systems}},'' \emph{IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems}, vol.~37, no.~11, pp. 2732--2742, Nov. 2018.

\bibitem{tann2016}
H.~Tann, S.~Hashemi, R.~I. Bahar, and S.~Reda, ``Runtime configurable deep neural networks for energy-accuracy trade-off,'' in \emph{Proceedings of the {{Eleventh IEEE}}/{{ACM}}/{{IFIP International Conference}} on {{Hardware}}/{{Software Codesign}} and {{System Synthesis}}}, ser. {{CODES}} '16.\hskip 1em plus 0.5em minus 0.4em\relax New York, NY, USA: Association for Computing Machinery, Oct. 2016, pp. 1--10.

\bibitem{yu2018}
J.~Yu, L.~Yang, N.~Xu, J.~Yang, and T.~Huang, ``Slimmable {{Neural Networks}},'' in \emph{2019 {{International Conference}} on {{Learning Representations}} ({{ICLR}})}, Dec. 2018.

\bibitem{feurer2019}
M.~Feurer and F.~Hutter, ``Hyperparameter {{Optimization}},'' in \emph{Automated {{Machine Learning}}: {{Methods}}, {{Systems}}, {{Challenges}}}, F.~Hutter, L.~Kotthoff, and J.~Vanschoren, Eds.\hskip 1em plus 0.5em minus 0.4em\relax Cham: Springer International Publishing, 2019, pp. 3--33.

\bibitem{erickson2021}
B.~J. Erickson and F.~Kitamura, ``Magician's {{Corner}}: 9. {{Performance Metrics}} for {{Machine Learning Models}},'' \emph{Radiology: Artificial Intelligence}, vol.~3, no.~3, p. e200126, May 2021.

\bibitem{hastie2009}
T.~Hastie, R.~Tibshirani, and J.~Friedman, \emph{The {{Elements}} of {{Statistical Learning}}}, ser. Springer {{Series}} in {{Statistics}}.\hskip 1em plus 0.5em minus 0.4em\relax New York, NY: Springer, 2009.

\bibitem{dessain2022}
J.~Dessain, ``Machine learning models predicting returns: {{Why}} most popular performance metrics are misleading and proposal for an efficient metric,'' \emph{Expert Systems with Applications}, vol. 199, p. 116970, Aug. 2022.

\bibitem{grandini2020}
M.~Grandini, E.~Bagli, and G.~Visani, ``Metrics for {{Multi-Class Classification}}: An {{Overview}},'' arXiv, White {{Paper}} arXiv:2008.05756, Aug. 2020.

\bibitem{fagin2002}
R.~Fagin, ``Combining fuzzy information: An overview,'' \emph{ACM SIGMOD Record}, vol.~31, no.~2, pp. 109--118, Jun. 2002.

\bibitem{ilyas2008}
I.~F. Ilyas, G.~Beskales, and M.~A. Soliman, ``A survey of top- {\emph{k}} query processing techniques in relational database systems,'' \emph{ACM Computing Surveys}, vol.~40, no.~4, pp. 1--58, Oct. 2008.

\bibitem{li2006}
C.~Li, K.~{Chen-Chuan Chang}, and I.~F. Ilyas, ``Supporting ad-hoc ranking aggregates,'' in \emph{Proceedings of the 2006 {{ACM SIGMOD}} International Conference on {{Management}} of Data}.\hskip 1em plus 0.5em minus 0.4em\relax Chicago IL USA: ACM, Jun. 2006, pp. 61--72.

\bibitem{borzsony2001}
S.~Borzsony, D.~Kossmann, and K.~Stocker, ``The {{Skyline}} operator,'' in \emph{Proceedings 17th {{International Conference}} on {{Data Engineering}}}.\hskip 1em plus 0.5em minus 0.4em\relax Heidelberg, Germany: IEEE Comput. Soc, 2001, pp. 421--430.

\bibitem{dehghani2019}
A.~Dehghani, O.~Sarbishei, T.~Glatard, and E.~Shihab, ``A {{Quantitative Comparison}} of {{Overlapping}} and {{Non-Overlapping Sliding Windows}} for {{Human Activity Recognition Using Inertial Sensors}},'' \emph{Sensors (Basel, Switzerland)}, vol.~19, no.~22, p. 5026, Nov. 2019.

\bibitem{eibe2016}
F.~Eibe, M.~A. Hall, and I.~H. Witten, ``The {{WEKA Workbench}},'' in \emph{Data {{Mining}}: {{Practical Machine Learning Tools}} and {{Techniques}}}, fourth edition~ed.\hskip 1em plus 0.5em minus 0.4em\relax Morgan Kaufmann, 2016.

\bibitem{silberschatz2010}
A.~Silberschatz, H.~F. Korth, and S.~Sudarshan, \emph{{Database System Concepts}}, 6th~ed.\hskip 1em plus 0.5em minus 0.4em\relax New York: McGraw Hill Higher Education, Jan. 2010.

\bibitem{mckinney2022}
W.~McKinney, \emph{{Python for Data Analysis: Data Wrangling with Pandas, NumPy, and Jupyter}}, 3rd~ed.\hskip 1em plus 0.5em minus 0.4em\relax Beijing Boston Farnham Sebastopol Tokyo: O'Reilly Media, Sep. 2022.

\bibitem{marco2019}
V.~S. Marco, B.~Taylor, Z.~Wang, and Y.~Elkhatib, ``Optimizing {{Deep Learning Inference}} on {{Embedded Systems Through Adaptive Model Selection}},'' Nov. 2019.

\end{thebibliography}
